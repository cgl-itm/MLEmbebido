# Knowledge Distillation

## Articles
* [A Comprehensive Review of Knowledge Distillation in Computer Vision
](https://arxiv.org/abs/2404.00936)
* [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)

## PyTorch
* [Knowledge Distillation Tutorial](https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html)

## Blogs
* [Tutorial - Distilling Knowledge in Neural Networks With Weights & Biases](https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Deep-Neural-Networks--VmlldzoyMjkxODk)
* [Nvidia - How to Prune and Distill Llama-3.1 8B to an NVIDIA Llama-3.1-Minitron 4B Model](https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model/)
* [Comprehensive Review of Knowledge Distillation Techniques](https://medium.com/@aisagescribe/comprehensive-review-of-knowledge-distillation-techniques-40bcc22515c1)
* [Roboflow - What is knowledge distillation](https://blog.roboflow.com/what-is-knowledge-distillation/)
* [Build Powerful Lightweight Models Using Knowledge Distillation](https://towardsdatascience.com/build-powerful-lightweight-models-using-knowledge-distillation-618f69b569d9)
* [From TensorFlow to TFLite](https://medium.com/@zone24x7_inc/from-tensorflow-to-tflite-how-model-conversion-is-done-and-how-it-affects-neural-network-structure-1d01086083e0)
* [What is Quantization and Distillation of Models ?](https://medium.com/aimonks/what-is-quantization-and-distillation-of-models-a67e3a2dc325)
* [Seungki Kim](https://medium.com/@poperson1205)

## YouTube
* [Knowledge Distillation in Deep Neural Network](https://www.youtube.com/watch?v=83FFn7GqLu0)
* [Better not Bigger: Distilling LLMs into Specialized Models](https://www.youtube.com/watch?v=TIqf4LMNCjU)

## Repositories
* [Knowledge-Distillation-in-Keras](https://github.com/sayakpaul/Knowledge-Distillation-in-Keras/tree/master)
* [Repositorio completo](https://github.com/dkozlov/awesome-knowledge-distillation)
* [TorchDistill](https://github.com/yoshitomo-matsubara/torchdistill)
